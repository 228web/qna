{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')  # Run this only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix is now tmp/0-0\n"
     ]
    }
   ],
   "source": [
    "from my_io import Dataset\n",
    "dataset = Dataset('fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = []\n",
    "with open('/Users/jin/Sites/mangaki/data/ratings-ml.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for user_id, work_id, rating in reader:\n",
    "        triplets.append([int(user_id), int(work_id), 1 if float(rating) >= 2.5 else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = ShuffleSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_train, i_test in k_fold.split(triplets):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(triplets)[i_train]\n",
    "test = np.array(triplets)[i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#X = tf.constant(np.array(dataset.data).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def get_train_test(data):\n",
    "    n = len(data)\n",
    "    m = len(data[0])\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if random.random() < 0.9:\n",
    "                train.append((i, j, int(data[i][j])))\n",
    "            else:\n",
    "                test.append((i, j, int(data[i][j])))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base(i, d):\n",
    "    v = [0] * d\n",
    "    v[i] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_train_test(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_USERS = 1 + max(max(train[:, 0]), max(test[:, 0]))\n",
    "NB_WORKS = 1 + max(max(train[:, 1]), max(test[:, 1]))\n",
    "\n",
    "def make_hot(triplets):\n",
    "    data = []\n",
    "    for i, j, v in triplets:\n",
    "        data.append((base(i, NB_USERS), base(j, NB_WORKS), v))\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield len(l[i:i + n]), l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data):\n",
    "    return list(map(np.array, zip(*data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_hot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = NB_USERS\n",
    "R = 20\n",
    "M = NB_WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = tf.Variable(tf.random_normal([N, R]), name='U')\n",
    "V = tf.Variable(tf.random_normal([R, M]), name='V')\n",
    "bias = tf.Variable(tf.random_normal([M, 1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "E = tf.placeholder(tf.float32, shape=(None, N))\n",
    "F = tf.placeholder(tf.float32, shape=(None, M))\n",
    "T = tf.placeholder(tf.float32, shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_without_bias = tf.reduce_sum(tf.matmul(E, U) * tf.matmul(F, tf.transpose(V)), axis=1)\n",
    "pred = pred_without_bias + tf.reduce_sum(tf.matmul(F, bias), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=T, logits=pred))\n",
    "regularized_loss = (loss + 0.01 * tf.reduce_mean(tf.square(U))\n",
    "                         + 0.01 * tf.reduce_mean(tf.abs(V))\n",
    "                         + 0.01 * tf.reduce_mean(tf.square(bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_step = optimizer.minimize(regularized_loss, var_list=[U, V, bias])\n",
    "#train_V_step = optimizer.minimize(negative_log_likelihood, var_list=[V])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = make_hot(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(20):\n",
    "    for size, chunk in chunks(data, BATCH_SIZE):\n",
    "        if size < BATCH_SIZE:\n",
    "            break\n",
    "        eb, fb, vb = get_batches(chunk)\n",
    "        sess.run(train_step, feed_dict={E: eb, F: fb, T: vb})\n",
    "        #print(sess.run(loss, feed_dict={E: eb, F: fb, T: vb}))\n",
    "\n",
    "    if iteration % 1 == 0:\n",
    "        eb, fb, vb = get_batches(test_data)\n",
    "        print(iteration, sess.run(loss, feed_dict={E: eb, F: fb, T: vb}))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bonne nouvelle, c'est qu'on obtient une log-likelihood de -3606 en 20 itérations alors que je viens de check, le package R converge au bout de 210 itérations vers une log-likelihood de -4454."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reste à savoir si ça généralise bien. (Le package R lui suppose un prior bayésien sur les compétences des gens.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.92225617e-01,   7.57199168e-01,   2.99945354e-01,\n",
       "          1.26648080e+00,   8.36898029e-01,   7.46591032e-01,\n",
       "          5.75143278e-01,   5.81251383e-01],\n",
       "       [  5.69952667e-01,   9.71436977e-01,   4.82483119e-01,\n",
       "          1.65013766e+00,   1.00464725e+00,   8.38633776e-01,\n",
       "          3.42653811e-01,   3.41077089e-01],\n",
       "       [  5.75150549e-01,   4.04434323e-01,   4.55957234e-01,\n",
       "          7.02938914e-01,   7.80022323e-01,   7.22231090e-01,\n",
       "          7.50544131e-01,   6.22578025e-01],\n",
       "       [  6.33334458e-01,   4.12763625e-01,   4.64858294e-01,\n",
       "          2.71402687e-01,   4.97841388e-01,   1.91181988e-01,\n",
       "          8.77478123e-02,   7.52362609e-01],\n",
       "       [  1.95949644e-01,   3.03780377e-01,   2.94619501e-01,\n",
       "          3.12623233e-01,   7.60286033e-01,   2.62267590e-01,\n",
       "          1.30510494e-01,   2.11985722e-01],\n",
       "       [  5.13305902e-01,   6.01617277e-01,   1.24468535e-01,\n",
       "          6.20978296e-01,   3.03121835e-01,   1.04155182e-03,\n",
       "          4.01907325e-01,   4.99788433e-01],\n",
       "       [  5.89385688e-01,   5.29471576e-01,   7.95729816e-01,\n",
       "          3.94571453e-01,   7.55055606e-01,   8.10524702e-01,\n",
       "          1.24419677e+00,   3.07154238e-01],\n",
       "       [  1.74940869e-01,   6.50937498e-01,   7.63698146e-02,\n",
       "          4.23339546e-01,   3.87430012e-01,   1.70662284e-01,\n",
       "          7.37654045e-06,   2.08161876e-01],\n",
       "       [  1.57685131e-01,   2.74284363e-01,   8.02673921e-02,\n",
       "          7.13340104e-01,   5.62011600e-01,   5.98314047e-01,\n",
       "          2.36508980e-01,   6.36660075e-03],\n",
       "       [  1.71787512e+00,   7.30400205e-01,   3.66479605e-01,\n",
       "          4.19972509e-01,   1.50189662e+00,   8.42306912e-01,\n",
       "          7.18775749e-01,   1.30710793e+00],\n",
       "       [  1.20678878e+00,   7.41012871e-01,   9.60824490e-01,\n",
       "          1.46990985e-01,   9.15246606e-01,   7.61553466e-01,\n",
       "          6.09046638e-01,   5.45576811e-01],\n",
       "       [  1.62039767e-04,   7.71421731e-01,   1.09291375e-02,\n",
       "          3.35589975e-01,   7.42716730e-01,   4.44904994e-03,\n",
       "          7.28015780e-01,   1.22782350e+00],\n",
       "       [  9.59869146e-01,   4.11365747e-01,   1.25723600e+00,\n",
       "          3.83434325e-01,   7.80604005e-01,   6.23777986e-01,\n",
       "          7.37758696e-01,   2.30177846e-02],\n",
       "       [  4.02227700e-01,   5.86699963e-01,   2.55912989e-01,\n",
       "          6.32160306e-01,   1.31521976e+00,   4.57581431e-01,\n",
       "          1.91976368e+00,   1.59105790e+00],\n",
       "       [  8.34846437e-01,   3.66206974e-01,   4.47915882e-01,\n",
       "          6.36665106e-01,   8.93796623e-01,   6.25745535e-01,\n",
       "          7.25877464e-01,   4.33480978e-01],\n",
       "       [  1.20344543e+00,   5.39529800e-01,   7.72145748e-01,\n",
       "          5.96834838e-01,   9.38763440e-01,   2.38605410e-01,\n",
       "          4.49157953e-01,   5.87006092e-01],\n",
       "       [  1.20896506e+00,   6.81066215e-01,   6.67261720e-01,\n",
       "          3.04052979e-01,   1.06236088e+00,   7.16749310e-01,\n",
       "          6.95332527e-01,   6.93420589e-01],\n",
       "       [  7.83519685e-01,   8.04185450e-01,   1.42273903e+00,\n",
       "          3.54780734e-01,   7.44395077e-01,   1.00545382e+00,\n",
       "          6.25730932e-01,   3.12805206e-01],\n",
       "       [  6.97328031e-01,   7.22059514e-03,   6.35958612e-01,\n",
       "          4.89169247e-02,   7.10838437e-01,   6.80338800e-01,\n",
       "          4.87609178e-01,   4.87845950e-02],\n",
       "       [  7.74416566e-01,   4.47976053e-01,   6.87217236e-01,\n",
       "          2.60782272e-01,   8.44464242e-01,   9.68243599e-01,\n",
       "          4.15793329e-01,   2.23415822e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.transpose(tf.abs(V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_7:0' shape=(536, 20) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
